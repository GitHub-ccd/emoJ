{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# emoJ\n",
    "\n",
    "# vision:\n",
    "Facial Expression or Facial Emotion Detector can be used to know whether a person is sad, happy, angry and so on only through his/her face. This Repository can be used to carry out such a task. It uses your WebCamera and then identifies your expression in Real Time. Yeah in real-time!\n",
    "Socrates said **“To know thyself is the beginning of wisdom”**. Thus, we use journals, blogs, vlogs and other tools to record and track ourselves to know ourselves better. As the saying goes **“A picture is worth a 1000 words”**, and detecting human emotion from a picture or a video feed is one of the most active fields in computer vision today.  We can leverage the computer vision technology to evaluate, record and track our own emotional state in our daily lives. Therefore, I propose to build an app that can train, re-train CNN with the use of transfer learning to record and track one's own emotion in an emotion-journal or an e-journal if you will. . \n",
    "\n",
    "\n",
    "# PLAN\n",
    "\n",
    "This is a three step process. In the first, we load the XML file for detecting the presence of faces and then we retrain our network with our image on five diffrent categories. After that, we import the label_image.py program from the [last video]() and set up everything in realtime.\n",
    "\n",
    "# DEPENDENCIES\n",
    "\n",
    "Hit the following in CMD/Terminal if you don't have already them installed:\n",
    "\n",
    "    pip install tensorflow\n",
    "    pip install opencv-python\n",
    "    \n",
    "That's it for now.\n",
    "\n",
    "So let's take a brief look at each step.\n",
    "\n",
    "## STEP 1 - Implementation of OpenCV HAAR CASCADES\n",
    "\n",
    "I'm using the \"Frontal Face Alt\" Classifier for detecting the presence of Face in the WebCam. This file is included with this repository. You can find the other classifiers [here](https://github.com/opencv/opencv/tree/master/data/haarcascades).\n",
    "\n",
    "Next, we have the task to load this file, which can be found in the [label.py](https://github.com/MauryaRitesh/Facial-Expression-Detection/blob/master/label.py) program. E.g.:\n",
    "\n",
    "    # We load the xml file\n",
    "    classifier = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "Now everything can be set with the Label.py Program. So let's move to the next Step.\n",
    "\n",
    "## STEP 2 - ReTraining the Network - Tensorflow Image Classifier\n",
    "\n",
    "We are going to create an Image classifier that identifies whether a person is sad, happy and so on and then show this text on the OpenCV Window.\n",
    "This step will consist of several sub steps:\n",
    "\n",
    "- We need to first create a directory named images. In this directory, create five or six sub directories with names like Happy, Sad, Angry, Calm and Neutral. You can add more than this.\n",
    "- Now fill these directories with respective images by downloading them from the Internet. E.g., In \"Happy\" directory, fill only those iages of person who are happy.\n",
    "- Now run the \"face-crop.py\" program as suggested in the [video](https://youtu.be/Dqa-3N8VZbw)\n",
    "- Once you have only cleaned images, you are ready to retrain the network. For this purpose I'm using Mobilenet Model which is quite fast and accurate. To run the training, hit the got to the parent folder and open CMD/Terminal here and hit the following:\n",
    "\n",
    "      python retrain.py --output_graph=retrained_graph.pb --output_labels=retrained_labels.txt --architecture=MobileNet_1.0_224 --image_dir=images\n",
    "\n",
    "That's it for this Step.\n",
    "\n",
    "## STEP 3 - Importing the ReTrained Model and Setting Everything Up\n",
    "\n",
    "Finally, I've put everything under the \"label_image.py\" file from where you can get evrything.\n",
    "Now run the \"label.py\" program by typing the following in CMD/Terminal:\n",
    "      \n",
    "     python label.py\n",
    "     \n",
    "It'll open a new window of OpenCV and then identifies your Facial Expression.\n",
    "We are done now!\n",
    "\n",
    "\n",
    "PLEASE DO STAR THIS REPO IF YOU FOUND SOMETHING INTERESTING. <3 Each Viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MLweb] *",
   "language": "python",
   "name": "conda-env-MLweb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
